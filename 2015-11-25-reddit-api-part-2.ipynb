{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Analysing reddit data - part 2: extracting the data  \n",
    "date: 2015-11-25  \n",
    "comments: false  \n",
    "tags: Python, Programming tips, Public Data, Reddit API, pandas  \n",
    "keywords: python, programming, reproducible research  \n",
    "\n",
    "---\n",
    "\n",
    "In [last week's post]({filename}2015-11-18-reddit-api-part-1.md), we covered the basics of setting up our environment so we can extract data from reddit. Now it's time to start on the meat of this topic. This week I will show you how to use the reddit public API to retrieve JSON-encoded data from the subreddit /r/relationships, although this technique will translate to both the reddit mainpage and other subreddits. As I mentioned last week, this is aimed at people who are completely new to working with JSON data, so we will go through everything step-by-step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up\n",
    "\n",
    "To start, let's set up our environment and start a new Jupyter notebook. Last week, I described how to set up a virtualenv for this project using [Fish](http://fishshell.com/) and [virtualfish](http://virtualfish.readthedocs.org/en/latest/index.html) in OSX. With this set up, we start by navigating to the folder we have created for this project (I recommend a local Git repo) and entering our virtualenv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cd ~/Documents/reddit_api\n",
    "!vf activate reddit_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are in the virtualenv, we launch Jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ipython notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter will then open in your default browser. If you have an empty working directory, you will get something like this:\n",
    "\n",
    "<img src=\"/figure/Jupyter_screenshot_1.png\" title=\"Jupyter home screen\" alt=\"This is the blank Jupyter notebook homepage\" style=\"display: block; margin: auto;\" />\n",
    "\n",
    "To start a new notebook, simply click on 'New' and select 'Python 2' under 'Notebooks' in the resultant dropdown menu, as below:\n",
    "\n",
    "<img src=\"/figure/Jupyter_screenshot_2.png\" title=\"Starting new Jupyter notebook\" alt=\"This is how to start a new Jupyter notebook\" style=\"display: block; margin: auto;\" />\n",
    "\n",
    "To get out of Jupyter when you are finished, close the browser window and enter control-c at the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to retrieve JSON-encoded data from reddit\n",
    "\n",
    "Accessing the (publically-available) data from reddit is done using the [Reddit API](https://www.reddit.com/dev/api). \n",
    "In this post, we will be looking at the most popular posts of all time on /r/relationships. We can access these using the request [https://www.reddit.com/r/relationships/top/](https://www.reddit.com/r/relationships/top/). Below is a sample of this page at the time I accessed it: \n",
    "\n",
    "<img src=\"/figure/rrel_top_normal.png\" title=\"rrelationships top posts\" alt=\"Capture of the first page of the top posts from subreddit relationships\" style=\"display: block; margin: auto;\" />\n",
    "\n",
    "To retrieve the data in a JSON-encoded format, we simply add .json to the end of this request (i.e., [https://www.reddit.com/r/relationships/top/.json](https://www.reddit.com/r/relationships/top/.json)). However, there is an issue with this request. It is only giving us the top posts from the last 24 hours by default. You can see from the API documentation that this request is a listing, therefore it takes the parameters `after`, `before`, `limit`, `count` and `show`. There is also an additional parameter `t` not mentioned on this page, which limits the time period of the posts to show. So in order to get the top posts of all time, we change our request to [https://www.reddit.com/r/relationships/top/.json?sort=top&t=all](https://www.reddit.com/r/relationships/top/.json?sort=top&t=all). Additionally, if we want a specific number of requests (let's start with one), we add the limit parameter to get [https://www.reddit.com/r/relationships/top/.json?sort=top&t=all&limit=1](https://www.reddit.com/r/relationships/top/.json?sort=top&t=all). If we put this into our browser, we end up with the following:\n",
    "\n",
    "<img src=\"/figure/rrel_top_json.png\" title=\"rrelationships top post json\" alt=\"JSON-encoded data from the top post on subreddit relationships\" style=\"display: block; margin: auto;\" />\n",
    "\n",
    "Gahh, what happened here?! I am sure you can see snippets of the data you want in there but it's a mess. In order to start decoding this, let's move over to reading the data in with Python. We first need to load in the required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next need to send a GET request for the data we want. Before we can do this, we need have a look at the [rules](https://github.com/reddit/reddit/wiki/API) that reddit has set up for accessing their site. The two most important rules for our current exercise is a) that we need to create a unique UserAgent string, and b) that we need to limit the number of requests we send to less than 30 a minute (i.e., one every two seconds). reddit requires that the UserAgent string contains your username, so if you don't have a reddit account you will need to [sign up](https://www.reddit.com/register) so you can get one.\n",
    "\n",
    "We are now ready to send our GET request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdr = {'User-Agent': 'osx:r/relationships.single.result:v1.0 (by /u/PopularCactus)'}\n",
    "url = 'https://www.reddit.com/r/relationships/top/.json?sort=top&t=all&limit=1'\n",
    "req = urllib2.Request(url, headers=hdr)\n",
    "text_data = urllib2.urlopen(req).read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to convert this into JSON-encoded data, we need to run the loads method from the json module on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = json.loads(text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we call `dir` on the `data` object we just created, we can see that there is a method called `values`. If we call the values method on `data`, we can see that the contents of the post are contained in a series of nested dictionaries and lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Listing',\n",
       " {u'after': u't3_3hw1jh',\n",
       "  u'before': None,\n",
       "  u'children': [{u'data': {u'approved_by': None,\n",
       "     u'archived': False,\n",
       "     u'author': u'whenlifegivesyoushit',\n",
       "     u'author_flair_css_class': None,\n",
       "     u'author_flair_text': None,\n",
       "     u'banned_by': None,\n",
       "     u'clicked': False,\n",
       "     u'created': 1440191222.0,\n",
       "     u'created_utc': 1440187622.0,\n",
       "     u'distinguished': None,\n",
       "     u'domain': u'self.relationships',\n",
       "     u'downs': 0,\n",
       "     u'edited': 1443809894.0,\n",
       "     u'from': None,\n",
       "     u'from_id': None,\n",
       "     u'from_kind': None,\n",
       "     u'gilded': 11,\n",
       "     u'hidden': False,\n",
       "     u'hide_score': False,\n",
       "     u'id': u'3hw1jh',\n",
       "     u'is_self': True,\n",
       "     u'likes': None,\n",
       "     u'link_flair_css_class': u'm-it updates',\n",
       "     u'link_flair_text': u'Updates',\n",
       "     u'locked': False,\n",
       "     u'media': None,\n",
       "     u'media_embed': {},\n",
       "     u'mod_reports': [],\n",
       "     u'name': u't3_3hw1jh',\n",
       "     u'num_comments': 903,\n",
       "     u'num_reports': None,\n",
       "     u'over_18': False,\n",
       "     u'permalink': u'/r/relationships/comments/3hw1jh/updatemy_26_f_with_my_husband_29_m_1_year_he_has/',\n",
       "     u'quarantine': False,\n",
       "     u'removal_reason': None,\n",
       "     u'report_reasons': None,\n",
       "     u'saved': False,\n",
       "     u'score': 7751,\n",
       "     u'secure_media': None,\n",
       "     u'secure_media_embed': {},\n",
       "     u'selftext': u'[Original Post](https://www.reddit.com/r/relationships/comments/3dheie/my_26_f_with_my_husband_29_m_1_year_he_has_been/)\\n\\nSummary of Original Post- My husband was diagnosed with terminal cancer. After failure of chemo and other treatments, he was told he has about a month to live. I asked for advice on how to make this time count and all of you wonderful people gave some very good advice.\\n\\n\\nLet me begin by saying that as much as I was day dreaming that I\\'ll get to update everyone of a miraculous recovery my brave darling made, I had to wake up to the bitter reality. My husband passed away a few days ago. And just as a lot of you had warned me, with all the preparation in the world and a warning that not many are fortunate to receive, absolutely nothing about when it actually happened felt like I was at all ready. It may as easily have been sudden. He fought bravely to the end and I\\'m proud of his attitude. I\\'m happy he doesn\\'t have to suffer and put on a brave face for me anymore.\\n\\nI\\'m here to thank all of you. Despite what I said above about not feeling prepared, I do feel blessed for having got that time. We may not have completely finished \"the list\" but we sure got to do some of the things that the busy preoccupations of life in all its cruelty snatches from a lot of people. We may not be completely without regrets but we managed to make our list of \\'I wish I had\\'s a lot shorter than it would have been before the warning. So here I am to thank everyone who commented/replied/PMed on that post. It meant a lot to both of us. A sincere thanks to all of you.\\n\\nA special shout to a few people:\\nu/mistyranch for courage and sharing \\nu/mcdie88 for making me feel like a 100 years old (covered that milestone too as he insisted I will live his share too!)\\nu/tacofugitive for looking out for me\\nu/aaoun responsible for some high quality home made porn\\nu/dahlialia who irritated the hell out of my husband as I wanted answers to ALL the questions\\nu/emalen thanks to whom I thought about this part, the coping\\nu/whatsleftisrigh for instilling some pragmatism in me\\nu/ianoftawa thanks to whom unfinished business won\\'t be an issue\\nu/brandyelf who made X\\'mas come early this year\\nu/tenebrous1 who inspired a letter that I haven\\'t been able to read past two lines of\\nu/emlgsh whose words rung in my ears to keep me stronger on the bad days\\nu/throwyourtoothbrush without whose advice I would have tried to do it all on my own and made a mess for sure\\nu/tomyownrhythm who sure knows how to turn a good spin on the dark moments\\nu/daivyjones for the immense support\\nu/WeltallPrime for inspiring my very first novel\\nand so many others for all the wonderful advice, support and most importantly for sharing your stories, I can\\'t thank you enough. I\\'m sorry I can\\'t mention all of you here. Please know how much every word meant to me.\\n\\nHere\\'s an update of all the things we did end up doing (and I hope this will help someone else like us out there):\\n1. As suggested by a lot of you, pictures and videos. I have loads of data of him doing his daily chores to just snoring away next to me. And I still don\\'t think it\\'s enough. Do this, you may not have a warning, you may regret it if you don\\'t. A little background of me here, I\\'ve always been anti pictures, I would proudly say make memories not photo albums and that if something is important enough, you\\'ll remember it. While I still stand by that to a certain extent, I do condone finding that balance. I would charge my tab, turn on the camera and put it in our room. So I could enjoy him and then re enjoy our moments later. And we made the heavily suggested naughty videos as well. Fair warning, getting closure is important so don\\'t get drowned in these memories either. It\\'s too soon for me but I do understand the risks and will look out for myself.\\n2. Which brings me to my next point. Discussing the future. As much as one would want to avoid thinking about a life beyond the one they love the most, not thinking of it will make it that much harder when it inevitably comes. Here\\'s where all the advice on being practical was executed. Practicality on financial and emotional fronts; financial being having ALL the financial information including account numbers, passwords, life insurance policy details, wills and any debts and the latter being arranging for a therapist and talking about expectations from a partner after one is gone and discussing the kids futures, if any. He documented all the financial information and verified it twice, taught me how to access his bank\\'s site and wrote down a step by step guide on how to get the insurance money once he was gone. He wrote a letter addressed to my \"next spouse\" with all the not so easy to discover things about me that were wonderful and necessary, in his words. \\n3. I wrote a book about him. I\\'m an aspiring author and I\\'m proud to say that the love of my life is the sole reader of my only book.\\n4. Scrapbook. This was so fun! I collected screenshots of the best and meanest things we\\'ve ever said to each other, printed those, interspersed those with our pictures over the years in chronological order (starting with the cliched obligatory baby pictures), threw in a few lists I wrote out of top 9 dates, top 9 best sex, top 9 reasons I love him (both our birthdays fall on 9th) etc., mixed in a crossword puzzle he had to solve and our scrapbook was ready!\\n5. I named a star after him. I know this is slightly silly but now I can look at him whenever I want.\\n6. Needless to say, indefinite time off work, spent every waking moment in his arms and sleeping moment in his tightly wrapped arms. Yes, lots of cuddling and just being together.\\n7. Balcony picnic. This was an excellent idea. Stars, candlelight, good food and some good old fashioned open air sex\\n8. Speaking of which, lots of sex. \\n9. We discussed with his doctors and freezing his sperm was not a possibility at this stage so that couldn\\'t pan out. \\n10. The last life party. I wanted to call it The party that never ends but he played the cancer card so I was shot down. All his friends and family came over, everyone said a few things about and to him, nobody was allowed to cry, I told them I was spending a lot on the funeral and he was stealing my thunder by being a tear hogger. It was actually pretty nice with gag jokes from his goofy friends, something like a Halloween with a ghost attending but he\\'s friendly like Casper rather than being creepy/scary\\n11. Told him I loved him, constantly. And anything else that came to my mind that I wanted him to know! He was quite a sport about it and returned the favor.\\n12. We played cards together, watched football matches and his favorite shows together. Things he loves. Casually holding each other.\\n13. Festival week- a day designated to all the festivals. Milestone birthdays- video recording for each with a message \\n14. Cooked his favorite meals for him. He was my happy helper. He\\'d wash the tomatoes and I\\'d make the lasagna. He called me the food conjurer.\\n15. Made him wear his favorite shirts for several days so now they\\'ll smell like him for some time.\\n16. Knit him a sweater, made a portrait of his\\n17. Things very specific to him that he wanted to do- a small bucket list that I won\\'t bore you with\\n   \\nI feel like I\\'ve lived a lifetime in the last month. The quote about living each day like your last got realized. I made a lot of memories I\\'ll never forget. \\n\\nI want to say one more thing before I sign off. All those who have been patient enough to make it to this part of the post or impatient enough to skip to this part, thanks for reading. I have read a lot of things on this sub and unfortunately a majority of the things I read are escapist, overcautious and pessimistic. While I encourage the right of one to protect themselves from potential hurt, I do find the world hiding behind that right shying away from happiness and condemning others at the drop of a hat. Not meaning to sound preachy or claiming to know anyone\\'s personal situation, I do wish to say this..believe in people, believe in goodness, believe in second chances. My husband and I didn\\'t have it perfect, we had our rough patches and forgave each other for mistakes if the other truly showed repentance for them. I could have left him long back and I would have been in the same scenario I am today, leading a life without him. The difference is I would have chosen that in the former scenario whereas now I have to accept the situation. And being here I know I would give anything in the world for that choice right now, I\\'m so glad I was wise enough to look past his tiny flaws and  fill my life with moments of the absolutely wonderful loving man he is (was). Be vulnerable, take risks, get hurt, it\\'s part of being a human and it\\'s ok. As long as you\\'re not being downright stupid, harming yourself or those around you irreparably and not being codependent enabling someone\\'s flaws rather than accepting them, it\\'s ok to make mistakes, that\\'s how we learn and grow. And on the chance that it\\'s not a mistake, the potential upside is limitless.\\n\\nIn the comments of my original post, a lot of you wrote that you cried and told your SO you loved them or gave them a random hug much to their surprise. I\\'ll admit that those comments made me happier than anything else. That our story could inspire some bond somewhere to get stronger was the greatest compliment. So I request anyone reading this to do this today. Give your SO that surprise hug, tell them you love them. I wouldn\\'t wish what we went through on my worst enemy and I\\'m still glad I got that time. But most of you won\\'t. THIS time is that time for you. I\\'m sorry that for most of you, it will be sudden/painful and prolonged. Living your life like each day is your last is impractical. But living your relationship like each day is your last is the easiest and most comforting thing in the world. Hug them, hold them, tell them you love them... Cheers to all the love in the world.\\n\\nThank you all once again. \\n\\n**tl;dr**: My husband passed away, this update is to thank all of you for your wonderful advice and support\\n\\nEdit 1 : Thank you once again Reddit, for all the overwhelming response. Thanks for all the tears, all the hugs and all the support. Thanks for the PMs offering more support. And above all, thanks for our story helped make a difference in your life. I\\'m so grateful to each of you who\\'s vowed to work on their relationships and love their partners more. I\\'m trying to reply to each one of you kindhearted folks, apologies if I have missed out on anyone. Thank you for being with me in this time. Your thoughts, prayers and support means a lot to me.\\n\\nEdit 2 : For those requesting for a [picture](http://imgur.com/gallery/UrGLxAB/new)',\n",
       "     u'selftext_html': u'&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/relationships/comments/3dheie/my_26_f_with_my_husband_29_m_1_year_he_has_been/\"&gt;Original Post&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Summary of Original Post- My husband was diagnosed with terminal cancer. After failure of chemo and other treatments, he was told he has about a month to live. I asked for advice on how to make this time count and all of you wonderful people gave some very good advice.&lt;/p&gt;\\n\\n&lt;p&gt;Let me begin by saying that as much as I was day dreaming that I&amp;#39;ll get to update everyone of a miraculous recovery my brave darling made, I had to wake up to the bitter reality. My husband passed away a few days ago. And just as a lot of you had warned me, with all the preparation in the world and a warning that not many are fortunate to receive, absolutely nothing about when it actually happened felt like I was at all ready. It may as easily have been sudden. He fought bravely to the end and I&amp;#39;m proud of his attitude. I&amp;#39;m happy he doesn&amp;#39;t have to suffer and put on a brave face for me anymore.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m here to thank all of you. Despite what I said above about not feeling prepared, I do feel blessed for having got that time. We may not have completely finished &amp;quot;the list&amp;quot; but we sure got to do some of the things that the busy preoccupations of life in all its cruelty snatches from a lot of people. We may not be completely without regrets but we managed to make our list of &amp;#39;I wish I had&amp;#39;s a lot shorter than it would have been before the warning. So here I am to thank everyone who commented/replied/PMed on that post. It meant a lot to both of us. A sincere thanks to all of you.&lt;/p&gt;\\n\\n&lt;p&gt;A special shout to a few people:\\n&lt;a href=\"/u/mistyranch\"&gt;u/mistyranch&lt;/a&gt; for courage and sharing \\n&lt;a href=\"/u/mcdie88\"&gt;u/mcdie88&lt;/a&gt; for making me feel like a 100 years old (covered that milestone too as he insisted I will live his share too!)\\n&lt;a href=\"/u/tacofugitive\"&gt;u/tacofugitive&lt;/a&gt; for looking out for me\\n&lt;a href=\"/u/aaoun\"&gt;u/aaoun&lt;/a&gt; responsible for some high quality home made porn\\n&lt;a href=\"/u/dahlialia\"&gt;u/dahlialia&lt;/a&gt; who irritated the hell out of my husband as I wanted answers to ALL the questions\\n&lt;a href=\"/u/emalen\"&gt;u/emalen&lt;/a&gt; thanks to whom I thought about this part, the coping\\n&lt;a href=\"/u/whatsleftisrigh\"&gt;u/whatsleftisrigh&lt;/a&gt; for instilling some pragmatism in me\\n&lt;a href=\"/u/ianoftawa\"&gt;u/ianoftawa&lt;/a&gt; thanks to whom unfinished business won&amp;#39;t be an issue\\n&lt;a href=\"/u/brandyelf\"&gt;u/brandyelf&lt;/a&gt; who made X&amp;#39;mas come early this year\\n&lt;a href=\"/u/tenebrous1\"&gt;u/tenebrous1&lt;/a&gt; who inspired a letter that I haven&amp;#39;t been able to read past two lines of\\n&lt;a href=\"/u/emlgsh\"&gt;u/emlgsh&lt;/a&gt; whose words rung in my ears to keep me stronger on the bad days\\n&lt;a href=\"/u/throwyourtoothbrush\"&gt;u/throwyourtoothbrush&lt;/a&gt; without whose advice I would have tried to do it all on my own and made a mess for sure\\n&lt;a href=\"/u/tomyownrhythm\"&gt;u/tomyownrhythm&lt;/a&gt; who sure knows how to turn a good spin on the dark moments\\n&lt;a href=\"/u/daivyjones\"&gt;u/daivyjones&lt;/a&gt; for the immense support\\n&lt;a href=\"/u/WeltallPrime\"&gt;u/WeltallPrime&lt;/a&gt; for inspiring my very first novel\\nand so many others for all the wonderful advice, support and most importantly for sharing your stories, I can&amp;#39;t thank you enough. I&amp;#39;m sorry I can&amp;#39;t mention all of you here. Please know how much every word meant to me.&lt;/p&gt;\\n\\n&lt;p&gt;Here&amp;#39;s an update of all the things we did end up doing (and I hope this will help someone else like us out there):\\n1. As suggested by a lot of you, pictures and videos. I have loads of data of him doing his daily chores to just snoring away next to me. And I still don&amp;#39;t think it&amp;#39;s enough. Do this, you may not have a warning, you may regret it if you don&amp;#39;t. A little background of me here, I&amp;#39;ve always been anti pictures, I would proudly say make memories not photo albums and that if something is important enough, you&amp;#39;ll remember it. While I still stand by that to a certain extent, I do condone finding that balance. I would charge my tab, turn on the camera and put it in our room. So I could enjoy him and then re enjoy our moments later. And we made the heavily suggested naughty videos as well. Fair warning, getting closure is important so don&amp;#39;t get drowned in these memories either. It&amp;#39;s too soon for me but I do understand the risks and will look out for myself.\\n2. Which brings me to my next point. Discussing the future. As much as one would want to avoid thinking about a life beyond the one they love the most, not thinking of it will make it that much harder when it inevitably comes. Here&amp;#39;s where all the advice on being practical was executed. Practicality on financial and emotional fronts; financial being having ALL the financial information including account numbers, passwords, life insurance policy details, wills and any debts and the latter being arranging for a therapist and talking about expectations from a partner after one is gone and discussing the kids futures, if any. He documented all the financial information and verified it twice, taught me how to access his bank&amp;#39;s site and wrote down a step by step guide on how to get the insurance money once he was gone. He wrote a letter addressed to my &amp;quot;next spouse&amp;quot; with all the not so easy to discover things about me that were wonderful and necessary, in his words. \\n3. I wrote a book about him. I&amp;#39;m an aspiring author and I&amp;#39;m proud to say that the love of my life is the sole reader of my only book.\\n4. Scrapbook. This was so fun! I collected screenshots of the best and meanest things we&amp;#39;ve ever said to each other, printed those, interspersed those with our pictures over the years in chronological order (starting with the cliched obligatory baby pictures), threw in a few lists I wrote out of top 9 dates, top 9 best sex, top 9 reasons I love him (both our birthdays fall on 9th) etc., mixed in a crossword puzzle he had to solve and our scrapbook was ready!\\n5. I named a star after him. I know this is slightly silly but now I can look at him whenever I want.\\n6. Needless to say, indefinite time off work, spent every waking moment in his arms and sleeping moment in his tightly wrapped arms. Yes, lots of cuddling and just being together.\\n7. Balcony picnic. This was an excellent idea. Stars, candlelight, good food and some good old fashioned open air sex\\n8. Speaking of which, lots of sex. \\n9. We discussed with his doctors and freezing his sperm was not a possibility at this stage so that couldn&amp;#39;t pan out. \\n10. The last life party. I wanted to call it The party that never ends but he played the cancer card so I was shot down. All his friends and family came over, everyone said a few things about and to him, nobody was allowed to cry, I told them I was spending a lot on the funeral and he was stealing my thunder by being a tear hogger. It was actually pretty nice with gag jokes from his goofy friends, something like a Halloween with a ghost attending but he&amp;#39;s friendly like Casper rather than being creepy/scary\\n11. Told him I loved him, constantly. And anything else that came to my mind that I wanted him to know! He was quite a sport about it and returned the favor.\\n12. We played cards together, watched football matches and his favorite shows together. Things he loves. Casually holding each other.\\n13. Festival week- a day designated to all the festivals. Milestone birthdays- video recording for each with a message \\n14. Cooked his favorite meals for him. He was my happy helper. He&amp;#39;d wash the tomatoes and I&amp;#39;d make the lasagna. He called me the food conjurer.\\n15. Made him wear his favorite shirts for several days so now they&amp;#39;ll smell like him for some time.\\n16. Knit him a sweater, made a portrait of his\\n17. Things very specific to him that he wanted to do- a small bucket list that I won&amp;#39;t bore you with&lt;/p&gt;\\n\\n&lt;p&gt;I feel like I&amp;#39;ve lived a lifetime in the last month. The quote about living each day like your last got realized. I made a lot of memories I&amp;#39;ll never forget. &lt;/p&gt;\\n\\n&lt;p&gt;I want to say one more thing before I sign off. All those who have been patient enough to make it to this part of the post or impatient enough to skip to this part, thanks for reading. I have read a lot of things on this sub and unfortunately a majority of the things I read are escapist, overcautious and pessimistic. While I encourage the right of one to protect themselves from potential hurt, I do find the world hiding behind that right shying away from happiness and condemning others at the drop of a hat. Not meaning to sound preachy or claiming to know anyone&amp;#39;s personal situation, I do wish to say this..believe in people, believe in goodness, believe in second chances. My husband and I didn&amp;#39;t have it perfect, we had our rough patches and forgave each other for mistakes if the other truly showed repentance for them. I could have left him long back and I would have been in the same scenario I am today, leading a life without him. The difference is I would have chosen that in the former scenario whereas now I have to accept the situation. And being here I know I would give anything in the world for that choice right now, I&amp;#39;m so glad I was wise enough to look past his tiny flaws and  fill my life with moments of the absolutely wonderful loving man he is (was). Be vulnerable, take risks, get hurt, it&amp;#39;s part of being a human and it&amp;#39;s ok. As long as you&amp;#39;re not being downright stupid, harming yourself or those around you irreparably and not being codependent enabling someone&amp;#39;s flaws rather than accepting them, it&amp;#39;s ok to make mistakes, that&amp;#39;s how we learn and grow. And on the chance that it&amp;#39;s not a mistake, the potential upside is limitless.&lt;/p&gt;\\n\\n&lt;p&gt;In the comments of my original post, a lot of you wrote that you cried and told your SO you loved them or gave them a random hug much to their surprise. I&amp;#39;ll admit that those comments made me happier than anything else. That our story could inspire some bond somewhere to get stronger was the greatest compliment. So I request anyone reading this to do this today. Give your SO that surprise hug, tell them you love them. I wouldn&amp;#39;t wish what we went through on my worst enemy and I&amp;#39;m still glad I got that time. But most of you won&amp;#39;t. THIS time is that time for you. I&amp;#39;m sorry that for most of you, it will be sudden/painful and prolonged. Living your life like each day is your last is impractical. But living your relationship like each day is your last is the easiest and most comforting thing in the world. Hug them, hold them, tell them you love them... Cheers to all the love in the world.&lt;/p&gt;\\n\\n&lt;p&gt;Thank you all once again. &lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;tl;dr&lt;/strong&gt;: My husband passed away, this update is to thank all of you for your wonderful advice and support&lt;/p&gt;\\n\\n&lt;p&gt;Edit 1 : Thank you once again Reddit, for all the overwhelming response. Thanks for all the tears, all the hugs and all the support. Thanks for the PMs offering more support. And above all, thanks for our story helped make a difference in your life. I&amp;#39;m so grateful to each of you who&amp;#39;s vowed to work on their relationships and love their partners more. I&amp;#39;m trying to reply to each one of you kindhearted folks, apologies if I have missed out on anyone. Thank you for being with me in this time. Your thoughts, prayers and support means a lot to me.&lt;/p&gt;\\n\\n&lt;p&gt;Edit 2 : For those requesting for a &lt;a href=\"http://imgur.com/gallery/UrGLxAB/new\"&gt;picture&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;',\n",
       "     u'stickied': False,\n",
       "     u'subreddit': u'relationships',\n",
       "     u'subreddit_id': u't5_2qjvn',\n",
       "     u'suggested_sort': None,\n",
       "     u'thumbnail': u'',\n",
       "     u'title': u'[UPDATE]My [26 F] with my husband [29 M] 1 year, he has been diagnosed with terminal cancer, how to make it count?',\n",
       "     u'ups': 7751,\n",
       "     u'url': u'https://www.reddit.com/r/relationships/comments/3hw1jh/updatemy_26_f_with_my_husband_29_m_1_year_he_has/',\n",
       "     u'user_reports': [],\n",
       "     u'visited': False},\n",
       "    u'kind': u't3'}],\n",
       "  u'modhash': u''}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If, for example, we wanted to access the title of the post, it is nested within the following structure: ['Listing', {'children': [{'data': {'title':}}]}]. In other words, the nesting structure goes as follows: list -> dictionary -> list -> dictionary -> dictionary. We can therefore access it using a combination of list and dictionary indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'[UPDATE]My [26 F] with my husband [29 M] 1 year, he has been diagnosed with terminal cancer, how to make it count?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values()[1]['children'][0]['data']['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all of the other data we want is in the same dictionary as `title`, we simply need to exchange the `title` key for the relevant key. For example, the total post score is under the `score` key. Getting the specific data you might want from reddit is a matter of going through and matching the information in the dictionary to data in the post to figure out what is what.\n",
    "\n",
    "We now know how to extract information from a single post. Let's move up to extracting information from a larger number of posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting and storing larger quantities of data\n",
    "\n",
    "The methods above can be easily generalised in order to obtain larger quantities of data from reddit. However, there is one further hurdle to overcome. As you can see from the documentation, reddit only allows you to pull 100 posts at a time from the top board. We need some way of tracking the last post we get from each request and then starting the next request after this post. Luckily, each post has a unique identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u't3_3hw1jh'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values()[1]['children'][0]['data']['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simply couple this with the `after` parameter in a loop in order to get the number of posts we want. In other words, we will send a request for the first 100 posts, obtain the identifier of the final post in that request, and ask that the next request of 100 start at the first post after this post. In our case, let's extract the first 1000 posts. As part of extracting the data, we will keep only the content assigned to the `children` key in the first dictionary. This makes it possible to put all of the separate requests together in a collection (in this case, a list). In order to make sure we don't accidentally exceed reddit's request limit of 30 requests per minute, we'll use the `sleep` method from the `time` module to place a pause of 2 seconds in between each iteration of the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "hdr = {'User-Agent': 'osx:r/relationships.multiple.results:v1.0 (by /u/PopularCactus)'}\n",
    "url = 'https://www.reddit.com/r/relationships/top/.json?sort=top&t=all&limit=100'\n",
    "req = urllib2.Request(url, headers=hdr)\n",
    "text_data = urllib2.urlopen(req).read()\n",
    "data = json.loads(text_data)\n",
    "data_all = data.values()[1]['children']\n",
    "\n",
    "while (len(data_all) <= 1000):\n",
    "    time.sleep(2)\n",
    "    last = data_all[-1]['data']['name']\n",
    "    url = 'https://www.reddit.com/r/relationships/top/.json?sort=top&t=all&limit=100&after=%s' % last\n",
    "    req = urllib2.Request(url, headers=hdr)\n",
    "    text_data = urllib2.urlopen(req).read()\n",
    "    data = json.loads(text_data)\n",
    "    data_all += data.values()[1]['children']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we have retrieved the correct number of posts by checking the length of our list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data in raw JSON format, we can simply use another loop to extract the desired information from each post. In this case, I have decided to get the date of posting, title, flair, number of comments and total score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "article_title = []\n",
    "article_flairs = []\n",
    "article_date = []\n",
    "article_comments = []\n",
    "article_score = []\n",
    "\n",
    "for i in range(0, len(data_all)):\n",
    "    article_title.append(data_all[i]['data']['title'])\n",
    "    article_flairs.append(data_all[i]['data']['link_flair_text'])\n",
    "    article_date.append(data_all[i]['data']['created_utc'])\n",
    "    article_comments.append(data_all[i]['data']['num_comments'])\n",
    "    article_score.append(data_all[i]['data']['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're pretty much there! The final step is creating a `pandas DataFrame` using these lists of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "rel_df = DataFrame({'Date': article_date,\n",
    "                    'Title': article_title,\n",
    "                    'Flair': article_flairs,\n",
    "                    'Comments': article_comments,\n",
    "                    'Score': article_score})\n",
    "rel_df = rel_df[['Date', 'Title', 'Flair', 'Comments', 'Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Flair</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1440187622</td>\n",
       "      <td>[UPDATE]My [26 F] with my husband [29 M] 1 yea...</td>\n",
       "      <td>Updates</td>\n",
       "      <td>903</td>\n",
       "      <td>7755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1438962646</td>\n",
       "      <td>Update: I [30 F] am sitting in the back of my ...</td>\n",
       "      <td>◉ Locked Post ◉</td>\n",
       "      <td>631</td>\n",
       "      <td>6013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1435026034</td>\n",
       "      <td>UPDATE: My fiancee (24F) has no bridesmaids an...</td>\n",
       "      <td>Updates</td>\n",
       "      <td>623</td>\n",
       "      <td>5519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1438393090</td>\n",
       "      <td>My [42M] daughter [17F] has been bullying a gi...</td>\n",
       "      <td>◉ Locked Post ◉</td>\n",
       "      <td>972</td>\n",
       "      <td>5295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1440543117</td>\n",
       "      <td>[Update] My [26F] fiance's [28M] ex-wife [28F]...</td>\n",
       "      <td>Updates</td>\n",
       "      <td>768</td>\n",
       "      <td>5181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                              Title  \\\n",
       "0  1440187622  [UPDATE]My [26 F] with my husband [29 M] 1 yea...   \n",
       "1  1438962646  Update: I [30 F] am sitting in the back of my ...   \n",
       "2  1435026034  UPDATE: My fiancee (24F) has no bridesmaids an...   \n",
       "3  1438393090  My [42M] daughter [17F] has been bullying a gi...   \n",
       "4  1440543117  [Update] My [26F] fiance's [28M] ex-wife [28F]...   \n",
       "\n",
       "             Flair  Comments  Score  \n",
       "0          Updates       903   7755  \n",
       "1  ◉ Locked Post ◉       631   6013  \n",
       "2          Updates       623   5519  \n",
       "3  ◉ Locked Post ◉       972   5295  \n",
       "4          Updates       768   5181  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a `pandas DataFrame` that is ready for cleaning and analysis. Next week I will start with both cleaning problematic variables (e.g., converting `Date` into a datetime format and dealing with the \"Locked Post\" flairs) and extracting further data from these variables. I will finish this series doing some basic analyses and plotting with these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
