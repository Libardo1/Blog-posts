---
title: 'A Gentle Introduction to Standard Error and Bootstrapping'
output: html_document
---

Many of the points and code in this blog post are adapted from the excellent Statistical Inference [link] unit on Coursera by Brian Caffo, Jeff Leek and Roger Peng. This course gives a far more comprehensive coverage of this material and is highly recommended.

## What is the standard error of an estimate?

Suppose you want to assess the average number of page views a website has per day. How do you measure this? Well, the most logical thing to do is to take a representative sample e.g., a sequence of 30 days, record the number of page views, and take their mean. However, how do you know if this is a good estimate the true daily average number of page views? How do you know if a sample of this size is big enough?

The **standard error** of any statistic, is a measure of the amount of error in the sample statistic with respect to the true population value. In this case, the standard error of the mean would be an estimate of how accurately the daily page views of our sample reflects the true population mean. The smaller the standard error of the mean, the better the sample estimate reflects the true population value.

## Why should I care about the standard error?

It is tempting, once you get into applying statistics to a sample, to forget you are dealing with a representation of a population, rather than the population itself. As such, all statistics you derive using your sample are just estimates of the true population parameters you are hoping to talk about (although hopefully pretty accurate ones). It is therefore important that you have some idea how reliable these estimates are before you start making inferences from them.

## How is the standard error calculated?

One way of assessing the standard error of the mean is to sample repeated from the population, calculate the mean for each sample, and plot the distribution of these means. Each sample is expected to be a different representation of the population, with different estimates of the median in each sample. 

Imagine if you were working for a company that wanted to know how many page views their website received. One thing you could do is take a large number, say 1,000, samples of 30 day periods each. Instead of doing this (because it would take about 82 years...), let's pretend we already know the population rate (220 page views per day) and use this to simulate this result in R:

```{r, message = FALSE}
rm(list = ls())         # Clear the workspace
set.seed(567)           # Set seed to replicate random variable generation
mn_vector <- NULL      # Generate the median of each sample and store in a vector
sample_frame <- data.frame(row.names = seq(from = 1, to = 30, by = 1))
for (i in 1 : 1000) {
    s <- rpois(30, lambda = 220)
    sample_frame <- cbind(sample_frame, s)
    mn_vector <- c(mn_vector, mean(s))
}
names(sample_frame) <- paste0("n", seq(from = 1, to = 1000, by = 1))
```

For example, your first sample has a mean rate of `r round(mn_vector[1])` page views per day, and the second sample has a mean rate of `r round(mn_vector[2])` page views per day. Their distributions are demonstrated below:

Dark blue: #152C59 / 4E7A9E
Light blue: #294FB1 / 869EB1
Brown: #7A4705 / 8B5462
Orange: #C14704 / 804B0C

"#152C59",
	"#DFDBBE",
	"#AD9C89",
	"#61584C"

```{r, message = FALSE, fig.width = 13}
require(ggplot2); require(gridExtra)
g1 <- ggplot(data=sample_frame, aes(sample_frame$n1)) + 
        geom_histogram(aes(y = ..density..), 
                       binwidth = 4, fill="#6baed6", colour="#2171b5") +
        xlab("Sample heights") +
        ylab("Density") +
        theme_bw() +
        ggtitle("Sample 1") + 
        theme(plot.title = element_text(lineheight=1.1, face="bold"))

mean1 <- data.frame(Means="Theoretical mean", vals = 220)
mean2 <- data.frame(Means="Sample mean", vals = mean(sample_frame$n1))
means <- rbind(mean1, mean2)
                
g1 <- g1 + geom_vline(data=means, aes(xintercept=vals, linetype = Means, 
                             colour = Means), size = 1, show_guide = TRUE) + 
      scale_color_manual(values=c("Theoretical mean"="black", "Sample mean"="#021645")) +
      theme(legend.position="none")
            
g2 <- ggplot(data=sample_frame, aes(sample_frame$n2)) + 
        geom_histogram(aes(y = ..density..), 
                       binwidth = 4, fill="#6baed6", colour="#2171b5") +
        xlab("Sample heights") +
        ylab("Density") +
        theme_bw() +
        ggtitle("Sample 2") + 
        theme(plot.title = element_text(lineheight=1.1, face="bold"))

mean1 <- data.frame(Means="Theoretical mean", vals = 220)
mean2 <- data.frame(Means="Sample mean", vals = mean(sample_frame$n2))
means <- rbind(mean1, mean2)
                
g2 <- g2 + geom_vline(data=means, aes(xintercept=vals, linetype = Means, 
                             colour = Means), size = 1, show_guide = TRUE) + 
      scale_color_manual(values=c("Theoretical mean"="black", "Sample mean"="#021645")) +
      theme(legend.position="none")

grid.arrange(g1, g2, nrow = 1, ncol = 2)
```

As you can see, the sample mean (in red) almost completely mirrors the population mean (in black) in sample 1, but there is quite a bit of difference between the two values in sample two.

It turns out that the distribution of the mean of the samples is approximately normally distributed. This is the **Central Limit Theorem (CLT)**, wherein the distribution of means of repeated samples of independently and identically distributed (or _iid_) observations becomes normal at a sufficiently large sample size.

This can be seen in the histogram of the means of each sample:

```{r, message = FALSE, fig.width=11}
g3 <- ggplot(data=as.data.frame(mn_vector), aes(mn_vector)) + 
        geom_histogram(aes(y = ..density..), binwidth = 1, 
                 col = "black", 
                 fill = "#4797E5") + 
        xlab("Mean of each sample") + 
        ylab("Density") + 
        theme_bw() + 
        ggtitle("Distribution of Means of 1,000 Samples") + 
        theme(plot.title = element_text(lineheight=.8, face="bold")) + 
        geom_line(aes(y = ..density.., colour = "Empirical"), stat = "density") + 
        stat_function(fun = dnorm, aes(colour = "Normal"), 
                    arg = list(mean = 220, sd = sd(mn_vector))) + 
        scale_colour_manual(name = "Density", values = c("black", "red"))

print(g3)
```

The mean of this distribution should be a pretty close estimate of the sample mean - and it is in this case, equalling `r round(mean(mn_vector))`. If we take the standard deviation of this distribution, we get the standard error of the mean. In other words, because these means are normally distributed, $\pm$1 standard error around this distribution mean represents the range that 68% of the sample means falls within, $\pm$2 standard errors represents the range that 95% of the sample means falls within, and so on.

In our case, taking a sample of 30 days gives us a pretty accurate assessment of the sample mean, with 68% of our samples giving an estimate falling between `r round(mean(mn_vector) - sd(mn_vector))` and `r round(mean(mn_vector) + sd(mn_vector))`, and 95% of our values falling within `r round(mean(mn_vector) - 2 * sd(mn_vector))` and `r round(mean(mn_vector) + 2 * sd(mn_vector))`. This is a pretty tight band around our population mean of 220 page views per day, indicating that a sample of 30 gives a pretty good estimate of the mean.

```{r, fig.width=11}
g4 <- ggplot(data=as.data.frame(mn_vector), aes(mn_vector)) + 
        geom_histogram(aes(y = ..density..), binwidth = 1, 
                 col = "black", 
                 fill = "#4797E5") + 
        xlab("Mean of each sample") + 
        ylab("Density") + 
        theme_bw() + 
        ggtitle("Distribution of Means of 1,000 Samples") + 
        theme(plot.title = element_text(lineheight=.8, face="bold"))

sem1 <- data.frame(SEMs="+/- 1 SEM", 
                   vals = c(mean(mn_vector) - sd(mn_vector), 
                            mean(mn_vector) + sd(mn_vector)))
sem2 <- data.frame(SEMs="+/- 2 SEMs", 
                    vals = c(mean(mn_vector) - 2 * sd(mn_vector), 
                            mean(mn_vector) + 2 * sd(mn_vector)))
sems <- rbind(sem1, sem2)
                
g4 <- g4 + geom_vline(data=sems, aes(xintercept=vals, linetype = SEMs, 
                            colour = SEMs), size = 1, show_guide = TRUE) + 
      scale_color_manual(values=c("+/- 1 SEM"="black", 
                                  "+/- 2 SEMs"="red"))

print(g4)
```

## What if I only have one sample?

Obviously the above is more of a thought exercise than anything - in real life, we of course don't have the population distribution, and we also usually don't have the luxury of taking multiple samples. In what case, what do we do? One alternative is to simply calculate the sample error of the mean using the formula: [insert Poisson SEM formula]. However, an alternative is to _bootstrap_ using our population sample. Bootstrapping involves basically the same steps as above, except instead of sampling from the population distribution, we sample from our sample distribution.

Let's assume we've recorded the page views of our website for a 30 day period:
```{r}
set.seed(567)
sample <- rpois(30, lambda = 220)

g5 <- ggplot(data=as.data.frame(sample), aes(sample)) + 
        geom_histogram(aes(y = ..density..), binwidth = 6, 
                 col = "black", 
                 fill = "#4797E5") + 
        xlab("Number of page views per day") + 
        ylab("Density") + 
        theme_bw() + 
        ggtitle("Sample distribution of page views over 30 days") + 
        theme(plot.title = element_text(lineheight=.8, face="bold"))
```

The mean of this distribution is `r round(mean(sample))` page views per day, which is pretty much the population mean (which we would expect given the tight standard error around the mean we saw earlier).

To create a bootstrapped distribution of sample means, all we need to do is take repeated samples from this sample distribution _with replacement_ and take their means. The reason we must do this with replacement is because if we have a sample distribution of size, say 30, and we take a sample from this of size 30, we will just end up with the original sample! Importantly, this process rests on the assumption that our sample is a pretty accurate representation of our sample. We'll cover this point at the end of the blog post.

So let's do this in R. We will take our sample of 30 days of page views and take 1,000 samples from this with replacement.

```{r}
set.seed(567)
mn_vector <- NULL
resample_frame <- data.frame(row.names = seq(from = 1, to = 30, by = 1))
for (i in 1 : 1000) {
    s <- sample(sample, 30, replace = TRUE)
    resample_frame <- cbind(resample_frame, s)
    mn_vector <- c(mn_vector, mean(s))
}

names(resample_frame) <- paste0("n", seq(from = 1, to = 1000, by = 1))
```

As with sampling from the population, we can see we get variability in our estimate of the population mean from sample to sample. For example, the mean in resample 1 is `r round(mean(resample_frame$n1))`, and the mean from resample 2 is `r round(mean(resample_frame$n2))`

```{r, message = FALSE, fig.width = 13}
require(ggplot2); require(gridExtra)
g1 <- ggplot(data=resample_frame, aes(resample_frame$n1)) + 
        geom_histogram(aes(y = ..density..), 
                       binwidth = 5, fill="#4797E5", colour="black") +
        xlab("Sample heights") +
        ylab("Density") +
        theme_bw() +
        ggtitle("Sample 1") + 
        theme(plot.title = element_text(lineheight=1.1, face="bold"))

mean1 <- data.frame(Means="Theoretical mean", vals = 220)
mean2 <- data.frame(Means="Sample mean", vals = mean(resample_frame$n1))
means <- rbind(mean1, mean2)
                
g1 <- g1 + geom_vline(data=means, aes(xintercept=vals, linetype = Means, 
                             colour = Means), size = 1, show_guide = TRUE) + 
      scale_color_manual(values=c("Theoretical mean"="black", "Sample mean"="red")) +
      theme(legend.position="none")
            
g2 <- ggplot(data=resample_frame, aes(resample_frame$n2)) + 
        geom_histogram(aes(y = ..density..), 
                       binwidth = 5, fill="#4797E5", colour="black") +
        xlab("Sample heights") +
        ylab("Density") +
        theme_bw() +
        ggtitle("Sample 2") + 
        theme(plot.title = element_text(lineheight=1.1, face="bold"))

mean1 <- data.frame(Means="Theoretical mean", vals = 220)
mean2 <- data.frame(Means="Sample mean", vals = mean(resample_frame$n2))
means <- rbind(mean1, mean2)
                
g2 <- g2 + geom_vline(data=means, aes(xintercept=vals, linetype = Means, 
                             colour = Means), size = 1, show_guide = TRUE) + 
      scale_color_manual(values=c("Theoretical mean"="black", "Sample mean"="red")) +
      theme(legend.position="none")

grid.arrange(g1, g2, nrow = 1, ncol = 2)
```

As with the means of the samples drawn from the population mean, the resamples drawn from the sample mean also approximate the normal distribution:



## How do I know if my sample represents my population?

## Why would I bootstrap instead of simply calculating the SEM?

