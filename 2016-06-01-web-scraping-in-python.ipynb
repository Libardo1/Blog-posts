{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "title: Basic web scraping in Python  \n",
    "date: 2015-12-23  \n",
    "comments: false  \n",
    "tags: Python, web scraping\n",
    "keywords: python, programming, pandas, matplotlib, web scraping, movielens, christmas, sql  \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step as always with Python analyses is to set up a virtualenv. If you're unfamiliar with how to do this, [this blog post]({filename}2015-11-18-reddit-api-part-1.md) explains how (and I promise you will never want to go back to system-installing packages!). Once you're in your virtualenv, install the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install lxml\n",
    "!pip install cssselect\n",
    "!pip install requests\n",
    "!pip install jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then enter `!ipython notebook` into the command line and start a new notebook (alternatively you can use your preferred Python IDE). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "\n",
    "Once we're ready to go, we first import our newly imported packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "from lxml.cssselect import CSSSelector\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we need to do is find out where our titles are in the page. This is pretty straightforward in a browser that supports developer tools, like [Chrome](https://www.google.com/chrome/). With Chrome, we simply need to go to our list of top 50 movies, right click, and select \"Inspect\". This brings up the developer tools.\n",
    "\n",
    "<img src=\"/figure/web_scraping_inspect_element.png\" title=\"Inspect element button\" alt=\"Finding elements on page in Chrome.\" style=\"display: block; margin: auto;\" />\n",
    "\n",
    "As you can see in the image above, this opens up the developer tools on the right of the screen. In the image, I have also highlighted a button that allows you to specifically inspect an element of the page. If you click on this and select one of the movie titles, it will take you to the specific part of the page that contains the title, like so:\n",
    "\n",
    "<img src=\"/figure/web_scraping_title_element.png\" title=\"Inspect title\" alt=\"Finding 'The Santa Clause' title in the page.\" style=\"display: block; margin: auto;\" />\n",
    "\n",
    "Ah ha! We can see that the first title, 'The Santa Clause', is tagged as `div.feature-item__text h3 a`. However, looking through the rest of the movies (for example, `Joyeux NoÃ«l`) are tagged only as `div.feature-item__text h3`. Huh, that creates some problems. To get around this, the function below checks whether the title is tagged with `a` (the `anchor_elem` variable), and if so, it uses this as the title. Otherwise, it uses the `h3` tag at the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_title(node):\n",
    "    '''\n",
    "    Extracts the movie title from the URL http://www.timeout.com/london/film/the-50-best-christmas-movies\n",
    "    taking into account that some titles are tagged as h3, and some as h3 a.\n",
    "    '''\n",
    "    h3_elem = node.cssselect('div.feature-item__text h3')[0]\n",
    "    anchor_elem = h3_elem.cssselect('a')\n",
    "    if len(anchor_elem) == 0:\n",
    "        return h3_elem.text_content()\n",
    "    else:\n",
    "        return anchor_elem[0].text_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've set up where to look for the titles, we can extract the data from the website. The `requests.get()` function pulls the data from the website, and the `lxml.html.fromstring(r.text)` command parses the html into the `tree` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get data and transform to text\n",
    "r = requests.get(\"http://www.timeout.com/london/film/the-50-best-christmas-movies\")\n",
    "tree = lxml.html.fromstring(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now select the parts of the html we want. We can see in the screenshot above that the titles are contained within the `article.feature-item` tag, therefore we select all data under this tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items_selector = CSSSelector('article.feature-item')\n",
    "all_items = items_selector(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply our `get_title` function using list comprehension to the items we pulled out. Let's have a look at what we got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Santa Clause (1994)',\n",
       " 'Reindeer Games (2000)',\n",
       " 'The Family Stone (2005)',\n",
       " 'Love Actually (2003)',\n",
       " 'Merry Christmas Mr Lawrence (1983)',\n",
       " u'\\n                                            Joyeux No\\xebl (2005)\\n                                        ',\n",
       " '\\n                                            Christmas in Connecticut (1945)\\n                                        ',\n",
       " 'The Polar Express (2004)',\n",
       " 'A Christmas Story (1983)',\n",
       " 'The Holiday (2006)',\n",
       " 'Planes, Trains and Automobiles (1987)',\n",
       " 'Lethal Weapon (1987)',\n",
       " 'Ghostbusters II (1989)',\n",
       " '\\n                                            Prancer (1989)\\n                                        ',\n",
       " 'Holiday Inn (1942)',\n",
       " 'White Christmas (1954)',\n",
       " u'\\n                                            Mickey\\u2019s Christmas Carol (1983)\\n                                        ',\n",
       " u'National Lampoon\\u2019s Christmas Vacation (1989)',\n",
       " '\\n                                            Babes In Toyland (1934)\\n                                        ',\n",
       " u'\\n                                            \\u2019R-Xmas (2001)\\n                                        ',\n",
       " 'Meet Me In St Louis (1944)',\n",
       " 'About a Boy (2002)',\n",
       " 'Christmas Evil (1980)',\n",
       " 'Die Hard (1988)',\n",
       " 'Die Hard 2 (1990)',\n",
       " '\\n                                            A Christmas Carol (1938)\\n                                        ',\n",
       " 'While You Were Sleeping (1995)',\n",
       " 'Arthur Christmas (2011)',\n",
       " 'Trading Places (1983)',\n",
       " 'Brazil (1985)',\n",
       " u'Bridget Jones\\u2019 Diary (2001) ',\n",
       " 'The Nightmare Before Christmas (1993)',\n",
       " 'The Muppet Christmas Carol (1992)',\n",
       " 'How The Grinch Stole Christmas (2000)',\n",
       " 'The Long Kiss Goodnight (1996)',\n",
       " 'In Bruges (2008)',\n",
       " 'Miracle on 34th Street (1947)',\n",
       " 'The Chronicles Of Narnia: The Lion, The Witch and the Wardrobe (2005)',\n",
       " '8 Women (2001)',\n",
       " 'Scrooged (1988)',\n",
       " 'Batman Returns (1992)',\n",
       " 'A Charlie Brown Christmas (1965)',\n",
       " 'Kiss Kiss Bang Bang (2005)',\n",
       " 'The Snowman (1982)',\n",
       " 'Edward Scissorhands (1990)',\n",
       " 'Home Alone (1990)',\n",
       " 'Gremlins (1984)',\n",
       " 'Bad Santa (2003)',\n",
       " 'Elf (2003)',\n",
       " u'It\\u2019s a Wonderful Life (1946)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3_titles = [get_title(item) for item in all_items[0:50]]\n",
    "h3_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is a bit of a mess. To use it we need to clean it up using a bit of string manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Strip newline and whitespace from titles\n",
    "titles = [t.replace('\\n', '').strip() for t in h3_titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert from unicode and replace apostraphes\n",
    "titles = [t.encode('utf8').replace('\\xe2\\x80\\x99', '\\'') for t in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace titles in the form \"The [title]\" to \"[title], The\"\n",
    "import re\n",
    "for i, t in enumerate(titles):\n",
    "    if re.match(\"^The\", t):\n",
    "        t = re.sub(r'^The ', '', t)\n",
    "        titles[i] = t[:-7] + \", The\" + t[-7:]\n",
    " \n",
    "# Replace titles in the form \"A [title]\" to \"[title], A\"       \n",
    "for i, t in enumerate(titles):\n",
    "    if re.match(\"^A\", t):\n",
    "        t = re.sub(r'^A ', '', t)\n",
    "        titles[i] = t[:-7] + \", A\" + t[-7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change \"Joyeux NoÃ«l\" to just \"Joyeux\" due to special character matching issues        \n",
    "titles[5] = titles[5].replace('Joyeux No\\xc3\\xabl (2005)', \n",
    "                              'Joyeux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export to text file                              \n",
    "f = open(\"christmas_movies.txt\", \"w\")\n",
    "f.write(\"\\n\".join(map(lambda x: str(x), titles)))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
