---
title: "A Gentle Introduction to Bootstrapping"
output: html_document
---

In the previous post, I explained the general principles behind the **standard error of the mean** (or **SEM**). The idea underlying the SEM is that you take repeated samples from the population of interest, and take the standard deviation of the means of these samples. Formulas for the SEM are available for each distribution, and are robust _if your data meets the assumptions of that distribution._

## What if I'm not sure if my data meets the assumptions of a distribution?

You might have a case where the true population distribution of your sample doesn't meet the assumptions of the closest appropriate distribution. For example, you might be interested in describing the mean levels of depression in a population, which is naturally positively skewed (i.e., most people in a population have no or low scores on measures of depression):

```{r, message=FALSE}
require(fGarch)
set.seed(567)
depression <- rsnorm(100, mean = 4, sd = 1, xi = 3)
```

```{r, message=FALSE, echo=FALSE}
require(ggplot2); require(gridExtra)

barfill <- "#6baed6"
barlines <- "#2171b5"
line1 <- "black"
line2 <- "#FF0000"

g1 <- ggplot(data=as.data.frame(depression), aes(depression)) + 
        geom_histogram(aes(y = ..density..), binwidth = .5, 
                 col = barlines, 
                 fill = barfill) + 
        xlab("Depression scores") + 
        ylab("Density") + 
        theme_bw() + 
        ggtitle("Distribution of Scores on a Depression Scale") + 
        theme(plot.title = element_text(lineheight=.8, face="bold"))
        
print(g1)
```
    
In this case, using the SEM formula for the normal distribution would be inappropriate due to this skewness. Instead, you can create empirically derived SEMs using a technique called **bootstrapping.**
    
## What is bootstrapping?

Bootstrapping involves basically the same principle as calculating the SEM I described in the last post, except instead of sampling from the _population distribution_, we resample from our _sample distribution._

Let's revisit the example from the previous post. We've been asked to calculate the average number of page views a website receives per day. We decided to record the daily number of page views over a 30-day period:

```{r}
# Setting seed and generating a single sample
set.seed(567)
sample <- rpois(30, lambda = 220)
```

```{r, message=FALSE, echo=FALSE}
# Plotting histogram of sample of daily page views
g1 <- ggplot(data=as.data.frame(sample), aes(sample)) + 
        geom_histogram(aes(y = ..density..), binwidth = 6, 
                 col = barlines, 
                 fill = barfill) + 
        xlab("Number of page views per day") + 
        ylab("Density") + 
        theme_bw() + 
        ggtitle("Sample distribution of page views over 30 days") + 
        theme(plot.title = element_text(lineheight=.8, face="bold"))

print(g1)
```

Although a Poisson distribution would be the most likely population distribution, we've decided we're not sure whether our number of page views meets the assumptions of this distribution. As such, we will bootstrap the SEM.

To create a bootstrapped distribution of sample means, all we need to do is take repeated resamples from this sample distribution _with replacement_ and take their means. The reason we must do this with replacement is because if we have a sample distribution of size, say 30, and we take a sample from this of size 30, we will just end up with the original sample! Importantly, this process rests on the assumption that our sample is a pretty accurate representation of our sample. We'll cover this point at the end of the blog post.

So let's do this in R. We will take our sample of 30 days of page views and take 1,000 samples from this with replacement.

```{r}
set.seed(567)
r_mn_vector <- NULL
resample_frame <- data.frame(row.names = seq(from = 1, to = 30, by = 1))
for (i in 1 : 1000) {
    s <- sample(sample, 30, replace = TRUE)
    resample_frame <- cbind(resample_frame, s)
    r_mn_vector <- c(r_mn_vector, mean(s))
}

names(resample_frame) <- paste0("n", seq(from = 1, to = 1000, by = 1))
```

As with sampling from the population, we can see we get variability in our estimate of the population mean from sample to sample. For example, the mean in resample 1 is `r round(mean(resample_frame$n1))`, and the mean from resample 2 is `r round(mean(resample_frame$n2))`.

```{r, message = FALSE, fig.width = 13}
g6 <- ggplot(data=resample_frame, aes(resample_frame$n1)) + 
        geom_histogram(aes(y = ..density..), 
                       binwidth = 5, fill = barfill, colour = barlines) +
        xlab("Sample heights") +
        ylab("Density") +
        theme_bw() +
        ggtitle("Sample 1") + 
        theme(plot.title = element_text(lineheight=1.1, face="bold"))

mean1 <- data.frame(Means="Theoretical mean", vals = 220)
mean2 <- data.frame(Means="Sample mean", vals = mean(resample_frame$n1))
means <- rbind(mean1, mean2)
                
g6 <- g6 + geom_vline(data=means, aes(xintercept=vals, linetype = Means, 
                             colour = Means), size = 1, show_guide = TRUE) + 
      scale_color_manual(values=c("Theoretical mean" = line1, "Sample mean" = line2)) +
      theme(legend.position="none")
            
g7 <- ggplot(data=resample_frame, aes(resample_frame$n2)) + 
        geom_histogram(aes(y = ..density..), 
                       binwidth = 5, fill = barfill, colour = barlines) +
        xlab("Sample heights") +
        ylab("Density") +
        theme_bw() +
        ggtitle("Sample 2") + 
        theme(plot.title = element_text(lineheight=1.1, face="bold"))

mean1 <- data.frame(Means="Theoretical mean", vals = 220)
mean2 <- data.frame(Means="Sample mean", vals = mean(resample_frame$n2))
means <- rbind(mean1, mean2)
                
g7 <- g7 + geom_vline(data=means, aes(xintercept=vals, linetype = Means, 
                             colour = Means), size = 1, show_guide = TRUE) + 
      scale_color_manual(values=c("Theoretical mean" = line1, "Sample mean" = line2)) +
      theme(legend.position="none")

grid.arrange(g6, g7, nrow = 1, ncol = 2)
```

As with the means of the samples drawn from the population mean, the resamples drawn from the sample mean also approximate the normal distribution:

```{r, fig.width=15}
g8 <- ggplot(data=as.data.frame(r_mn_vector), aes(r_mn_vector)) + 
        geom_histogram(aes(y = ..density..), binwidth = 1, 
                 col = barlines, 
                 fill = barfill) + 
        xlab("Mean of each sample") + 
        ylab("Density") + 
        theme_bw() + 
        ggtitle("Distribution of Means of 1,000 Samples") + 
        theme(plot.title = element_text(lineheight=.8, face="bold")) + 
        geom_line(aes(y = ..density.., colour = "Empirical"), stat = "density") + 
        stat_function(fun = dnorm, aes(colour = "Normal"), 
                    arg = list(mean = 220, sd = sd(mn_vector))) + 
        scale_colour_manual(name = "Density", values = c(line1, line2))

print(g8)
```

The bootstrapped SEM using 1,000 resamplings was `r round(sd(r_mn_vector), 2)`, which is extremely close to the SEM derived from sampling from the population (`r round(sd(mn_vector), 2)`). This is because the sample we took of daily page views was a good representation of the population.


## How do I know if my sample represents my population?

Choosing a good sample is less about number crunching and more about study design. Depending on the population of interest, it can be a bit tricky. Important elements of representative sampling include:  
1. **Sample size:** The trick to choosing a large enough sample size is making sure you gain sufficient information about the patterns you are trying to describe. For example, if we had only sampled 10 days, would that have been too small to avoid sampling extreme values by chance that threw off our estimate of the mean? If the event we were trying to sample was very rare (e.g., 1 event per 100 days), would sampling 30 days be long enough to assess its mean occurrence? However, the opposite consideration often occurs with sample size, where taking samples that are much larger than is needed is also undesirable as there may be time, monetary or even ethical reasons to limit the number of observations collected. For example, the company that asked us to assess page views would likely be unhappy if we spent 100 days collecting information on mean daily page views when the same question could be reliably answered from 30 days of data collection. There is a whole collection of methods that help you decide on the correct sample size (called **power**) which are beyond the scope of this already long blog post.
2. **Representativeness:** Another consideration is that we must make the data we collect a good reflection of the population we are trying to describe. Say that I tried to collect my data after a new campaign was launched advertising the website. This would not be a representative sample of the usual mean page views per day as page views are likely to be higher at that time.
3. **Measurement:** A final step in gaining a representative sample is remembering there may be a gap between a _concept_ of interest and the _method_ you need to use to measure it. In our example, there is likely to be little gap between what we are trying to measure (number of page views) and the method (a counter of page visitors). However, what if we don't actually care about page views per say, but the popularity of a website? Would it be reasonable to say that websites with higher mean page views have greater popularity?
